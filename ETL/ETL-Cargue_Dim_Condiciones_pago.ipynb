{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcY9y56n86vn"
   },
   "source": "ETL: Carga Areas de Servicio"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T13:39:56.271810Z",
     "start_time": "2024-11-16T13:39:56.268816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports \n",
    "from pyspark.sql.types import IntegerType, StringType, DateType, LongType\n",
    "from pyspark.sql import functions as f, SparkSession, types as t\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.functions import col, length\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T13:39:59.561504Z",
     "start_time": "2024-11-16T13:39:59.556957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MySQLConnector:\n",
    "    def __init__(self, spark: SparkSession, connection_properties: dict, url: str):\n",
    "        self.spark = spark\n",
    "        self.properties = connection_properties\n",
    "        self.url = url\n",
    "\n",
    "    def get_dataframe(self, sql_query: str):        \n",
    "        df = self.spark.read.jdbc(\n",
    "            url=self.url,\n",
    "            table=sql_query,\n",
    "            properties=self.properties\n",
    "        )\n",
    "        return df\n",
    "    \n",
    "    def save_db(self, df, tabla):\n",
    "        df.write.jdbc(\n",
    "            url=self.url,\n",
    "            table=tabla,\n",
    "            mode='append',\n",
    "            properties=self.properties\n",
    "        )\n",
    "        \n",
    "def create_spark_session(path_jar_driver):    \n",
    "    conf = SparkConf().set('spark.driver.extraClassPath', path_jar_driver)\n",
    "    spark_context = SparkContext(conf=conf)\n",
    "    sql_context = SQLContext(spark_context)\n",
    "    return sql_context.sparkSession    \n",
    "\n",
    "def get_dataframe_from_csv(_PATH, _sep):\n",
    "    return spark.read.load(_PATH, format=\"csv\", sep=_sep, inferSchema=\"true\", header='true')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "os1iJYmu86vt",
    "ExecuteTime": {
     "end_time": "2024-11-16T13:40:29.103266Z",
     "start_time": "2024-11-16T13:40:29.093571Z"
    }
   },
   "source": [
    "# LLENAR CON EL USUARIO DE CADA UNO\n",
    "db_user = ''\n",
    "db_psswd = ''\n",
    "\n",
    "\n",
    "connection_properties = {\n",
    "    \"user\": db_user,\n",
    "    \"password\": db_psswd,\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "source_db_string_connection = 'jdbc:mysql://157.253.236.120:8080/WWImportersTransactional'\n",
    "destination_db_string_connection = f'jdbc:mysql://157.253.236.120:8080/{db_user}'\n",
    "\n",
    "# Driver de conexion\n",
    "# LINUX\n",
    "path_jar_driver = '/opt/mysql/lib/mysql-connector-java-8.0.28.jar'\n",
    "# WINDOWS\n",
    "#path_jar_driver = 'C:\\Program Files (x86)\\MySQL\\Connector J 8.0\\mysql-connector-java-8.0.28.jar'"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T13:40:36.484852Z",
     "start_time": "2024-11-16T13:40:33.016452Z"
    }
   },
   "cell_type": "code",
   "source": "spark = create_spark_session(path_jar_driver)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/16 08:40:34 WARN Utils: Your hostname, willp resolves to a loopback address: 127.0.1.1; using 192.168.1.113 instead (on interface wlp9s0)\n",
      "24/11/16 08:40:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/16 08:40:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/home/willp/anaconda3/lib/python3.11/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T13:40:40.941673Z",
     "start_time": "2024-11-16T13:40:40.931528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn_orig = MySQLConnector(spark=spark, connection_properties=connection_properties, url=source_db_string_connection)\n",
    "conn_dest = MySQLConnector(spark=spark, connection_properties=connection_properties, url=destination_db_string_connection)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "LqQVz5s686vq"
   },
   "cell_type": "markdown",
   "source": "## Proceso de ETL para una dimensión."
  },
  {
   "metadata": {
    "id": "A2UT2Ia586vr"
   },
   "cell_type": "markdown",
   "source": "DESCRIPCION PROCESO"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhFsv4ba86vw"
   },
   "source": [
    "## Dimensión Condiciones de Pago\n",
    "\n",
    "\n",
    "AJUSTAR EL BLOQUE DEL DISENO PARA EL NUEVO MODELO DADO EN CLASE\n"
   ]
  },
  {
   "metadata": {
    "id": "UpOSEfhX86vs"
   },
   "cell_type": "markdown",
   "source": "![Modelo Movimientos](./images/CondPago.png)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extraction"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformation\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Carga Proveedores\n",
    "\n",
    "![Modelo Movimientos](./images/proveedor.png)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extraction"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load"
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vtE61qk986vx",
    "X9Oou0g986vy",
    "B5kFkHTD86vz",
    "ddFhEOmL86vz",
    "MuvVgJ4R86v0",
    "BZjDeVYd86v1",
    "_7xbgfCk86v1",
    "Rh_102Yy86v1",
    "HogvCqW_86v2",
    "9rKmT9jd86v2",
    "R9SnkMUH86v3",
    "k8O1GvOd86v3",
    "Mo633Vpg86v3",
    "i36NawhX86v4",
    "LvgnsPfK86v4",
    "dTv_CIOT86v5",
    "N9f10qpB86v9"
   ],
   "name": "MISW-ETL-TutorialETL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

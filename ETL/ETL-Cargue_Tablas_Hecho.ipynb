{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcY9y56n86vn"
   },
   "source": [
    "# Configuración Inicial\n",
    "Métodos un utils en común en los notebooks"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T01:44:12.519826Z",
     "start_time": "2024-11-19T01:44:12.416582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports \n",
    "from pyspark.sql.types import IntegerType, StringType, DateType, LongType\n",
    "from pyspark.sql import functions as f, SparkSession, types as t\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.functions import col, length\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T01:44:16.062314Z",
     "start_time": "2024-11-19T01:44:16.043020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MySQLConnector:\n",
    "    def __init__(self, spark: SparkSession, connection_properties: dict, url: str):\n",
    "        self.spark = spark\n",
    "        self.properties = connection_properties\n",
    "        self.url = url\n",
    "\n",
    "    def get_dataframe(self, sql_query: str):        \n",
    "        df = self.spark.read.jdbc(\n",
    "            url=self.url,\n",
    "            table=sql_query,\n",
    "            properties=self.properties\n",
    "        )\n",
    "        return df\n",
    "    \n",
    "    def save_db(self, df, tabla):\n",
    "        df.write.jdbc(\n",
    "            url=self.url,\n",
    "            table=tabla,\n",
    "            mode='append',\n",
    "            properties=self.properties\n",
    "        )\n",
    "        \n",
    "def create_spark_session(path_jar_driver):    \n",
    "    conf = SparkConf().set('spark.driver.extraClassPath', path_jar_driver)\n",
    "    spark_context = SparkContext(conf=conf)\n",
    "    sql_context = SQLContext(spark_context)\n",
    "    return sql_context.sparkSession    \n",
    "\n",
    "def get_dataframe_from_csv(_PATH, _sep):\n",
    "    return spark.read.load(_PATH, format=\"csv\", sep=_sep, inferSchema=\"true\", header='true')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "os1iJYmu86vt",
    "ExecuteTime": {
     "end_time": "2024-11-19T01:45:36.426024Z",
     "start_time": "2024-11-19T01:45:36.421612Z"
    }
   },
   "source": [
    "db_user = 'Estudiante_65_202415'\n",
    "db_psswd = 'Estudiante_202010409'\n",
    "\n",
    "connection_properties = {\n",
    "    \"user\": db_user,\n",
    "    \"password\": db_psswd,\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "source_db_string_connection = 'jdbc:mysql://157.253.236.120:8080/RaSaTransaccional_ETL'\n",
    "destination_db_string_connection = f'jdbc:mysql://157.253.236.120:8080/{db_user}'\n",
    "\n",
    "# Driver de conexion\n",
    "# LINUX\n",
    "path_jar_driver = '/opt/mysql/lib/mysql-connector-java-8.0.28.jar'\n",
    "# WINDOWS\n",
    "#path_jar_driver = 'C:\\Program Files (x86)\\MySQL\\Connector J 8.0\\mysql-connector-java-8.0.28.jar'"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T01:45:41.528405Z",
     "start_time": "2024-11-19T01:45:38.429670Z"
    }
   },
   "cell_type": "code",
   "source": "spark = create_spark_session(path_jar_driver)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/18 20:45:39 WARN Utils: Your hostname, willp resolves to a loopback address: 127.0.1.1; using 192.168.0.6 instead (on interface enp8s0)\n",
      "24/11/18 20:45:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/18 20:45:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/18 20:45:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "/home/willp/anaconda3/lib/python3.11/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "conn_orig = MySQLConnector(spark=spark, connection_properties=connection_properties, url=source_db_string_connection)\n",
    "conn_dest = MySQLConnector(spark=spark, connection_properties=connection_properties, url=destination_db_string_connection)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Consultar Dimensiones"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T02:07:05.721306Z",
     "start_time": "2024-11-19T02:07:05.655110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Areas de Servicio\n",
    "sql_dim_areas_servicio = '''(SELECT IdAreaDeServicio_DWH, IdAreaDeServicio_T FROM Rs_AreasDeServicio ORDER BY IdAreaDeServicio_DWH, IdAreaDeServicio_T) AS AreasDeServicio'''\n",
    "dim_areas_servicio = conn_dest.get_dataframe(sql_dim_areas_servicio)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T02:07:04.024787Z",
     "start_time": "2024-11-19T02:07:03.945473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Mini condiciones\n",
    "sql_dim_condiciones = '''(SELECT IdCondicionesBeneficios_DWH, IdTipoBeneficio_T, Annio FROM Rs_MiniCondicionesTipoBeneficio ORDER BY IdCondicionesBeneficios_DWH, IdTipoBeneficio_T, Annio) AS MiniCondicionesTipoBeneficio'''\n",
    "dim_mini_condiciones = conn_dest.get_dataframe(sql_dim_condiciones)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T02:07:49.089438Z",
     "start_time": "2024-11-19T02:07:49.017860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Proveedor\n",
    "sql_dim_proveedores = '''(SELECT IdProveedor_DWH, IdProveedor_T FROM Rs_Proveedor ORDER BY IdProveedor_DWH, IdProveedor_T) AS Proveedor'''\n",
    "dim_proveedores = conn_dest.get_dataframe(sql_dim_proveedores)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T02:09:15.355194Z",
     "start_time": "2024-11-19T02:09:15.293246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Niveles de Servicio\n",
    "sql_dim_nivel_servicio = '''(SELECT IdNivelDeServicio_DWH, IdNivelDeServicio_T FROM Rs_NivelesDeServicio ORDER BY IdNivelDeServicio_DWH, IdNivelDeServicio_T) AS NivelesDeServicio'''\n",
    "dim_nivel_servicio = conn_dest.get_dataframe(sql_dim_nivel_servicio)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T02:14:51.587192Z",
     "start_time": "2024-11-19T02:14:51.346099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tipos Beneficio\n",
    "sql_dim_tipos_beneficio = '''(SELECT IdTipoBeneficio_DWH, IdTipoBeneficio_T FROM Rs_TiposBeneficio ORDER BY IdTipoBeneficio_DWH, IdTipoBeneficio_T) AS TiposBeneficio'''\n",
    "dim_tipos_beneficio = conn_dest.get_dataframe(sql_dim_tipos_beneficio)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fecha\n",
    "sql_dim_fecha = '''(SELECT IdTipoBeneficio_DWH, IdTipoBeneficio_T FROM Rs_TiposBeneficio ORDER BY IdTipoBeneficio_DWH, IdTipoBeneficio_T) AS TiposBeneficio'''\n",
    "dim_tipos_beneficio = conn_dest.get_dataframe(sql_dim_tipos_beneficio)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hecho Planes tipo Beneficio"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vtE61qk986vx",
    "X9Oou0g986vy",
    "B5kFkHTD86vz",
    "ddFhEOmL86vz",
    "MuvVgJ4R86v0",
    "BZjDeVYd86v1",
    "_7xbgfCk86v1",
    "Rh_102Yy86v1",
    "HogvCqW_86v2",
    "9rKmT9jd86v2",
    "R9SnkMUH86v3",
    "k8O1GvOd86v3",
    "Mo633Vpg86v3",
    "i36NawhX86v4",
    "LvgnsPfK86v4",
    "dTv_CIOT86v5",
    "N9f10qpB86v9"
   ],
   "name": "MISW-ETL-TutorialETL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
